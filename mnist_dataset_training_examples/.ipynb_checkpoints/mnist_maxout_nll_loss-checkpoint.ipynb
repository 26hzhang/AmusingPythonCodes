{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./data/MNIST_data', one_hot=True)  # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01  # set learning rate\n",
    "epochs = 250  # set training epoches\n",
    "batch_size = 100  # set batch size\n",
    "# mnist data image of shape 28*28=784\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='inputs')\n",
    "# 0-9 digits recognition => 10 classes\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define maxout\n",
    "def max_out(inputs, num_units, axis=None):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if shape[0] is None:\n",
    "        shape[0] = -1\n",
    "    if axis is None:  # Assume that channel is the last dimension\n",
    "        axis = -1\n",
    "    num_channels = shape[axis]\n",
    "    if num_channels % num_units:\n",
    "        raise ValueError('number of features({}) is not '\n",
    "                         'a multiple of num_units({})'.format(num_channels, num_units))\n",
    "    shape[axis] = num_units\n",
    "    shape += [num_channels // num_units]\n",
    "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keep_dims=False)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define weight variable initializer\n",
    "def create_weight_variable(name, shape):\n",
    "    initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "    return tf.Variable(initializer(shape=shape), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define bias varibale initializer\n",
    "def create_bias_variable(name, shape):\n",
    "    initializer = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    return tf.Variable(initializer(shape=shape), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    W1 = create_weight_variable('Weights1', [784, 100])\n",
    "    b1 = create_bias_variable('Bias1', [100])\n",
    "    W2 = create_weight_variable('Weights2', [50, 10])\n",
    "    b2 = create_bias_variable('Bias2', [10])\n",
    "    t = max_out(tf.matmul(x, W1) + b1, 50)\n",
    "    return tf.nn.softmax(tf.matmul(t, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model and encapsulating all ops into scopes\n",
    "with tf.name_scope('predict'):\n",
    "    pred = make_predictions()\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=1))\n",
    "\n",
    "with tf.name_scope('sgd'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(accuracy, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 training cost= 0.992127061 test cost= 0.546172738\n",
      "Epoch: 0002 training cost= 0.486424812 test cost= 0.403940916\n",
      "Epoch: 0003 training cost= 0.394900460 test cost= 0.347531468\n",
      "Epoch: 0004 training cost= 0.349487334 test cost= 0.313572079\n",
      "Epoch: 0005 training cost= 0.319800078 test cost= 0.290561527\n",
      "Epoch: 0006 training cost= 0.298104208 test cost= 0.272943735\n",
      "Epoch: 0007 training cost= 0.280992032 test cost= 0.259365231\n",
      "Epoch: 0008 training cost= 0.267008742 test cost= 0.247563377\n",
      "Epoch: 0009 training cost= 0.255171297 test cost= 0.237542138\n",
      "Epoch: 0010 training cost= 0.244690942 test cost= 0.228677735\n",
      "Epoch: 0011 training cost= 0.235410459 test cost= 0.221095294\n",
      "Epoch: 0012 training cost= 0.227307682 test cost= 0.214637548\n",
      "Epoch: 0013 training cost= 0.219859619 test cost= 0.208010152\n",
      "Epoch: 0014 training cost= 0.213029524 test cost= 0.202875242\n",
      "Epoch: 0015 training cost= 0.206710415 test cost= 0.198648781\n",
      "Epoch: 0016 training cost= 0.200902558 test cost= 0.193033233\n",
      "Epoch: 0017 training cost= 0.195538817 test cost= 0.188659593\n",
      "Epoch: 0018 training cost= 0.190397111 test cost= 0.184512496\n",
      "Epoch: 0019 training cost= 0.185842764 test cost= 0.180759892\n",
      "Epoch: 0020 training cost= 0.181383379 test cost= 0.177581102\n",
      "Epoch: 0021 training cost= 0.177163734 test cost= 0.173869118\n",
      "Epoch: 0022 training cost= 0.173220955 test cost= 0.171027705\n",
      "Epoch: 0023 training cost= 0.169478162 test cost= 0.167899847\n",
      "Epoch: 0024 training cost= 0.165926350 test cost= 0.165556610\n",
      "Epoch: 0025 training cost= 0.162524190 test cost= 0.161963224\n",
      "Epoch: 0026 training cost= 0.159343261 test cost= 0.160695046\n",
      "Epoch: 0027 training cost= 0.156360903 test cost= 0.157468989\n",
      "Epoch: 0028 training cost= 0.153523689 test cost= 0.155469313\n",
      "Epoch: 0029 training cost= 0.150695310 test cost= 0.153194532\n",
      "Epoch: 0030 training cost= 0.147954805 test cost= 0.151286364\n",
      "Epoch: 0031 training cost= 0.145299403 test cost= 0.149869919\n",
      "Epoch: 0032 training cost= 0.142813476 test cost= 0.147479996\n",
      "Epoch: 0033 training cost= 0.140531973 test cost= 0.145810515\n",
      "Epoch: 0034 training cost= 0.138164846 test cost= 0.143673062\n",
      "Epoch: 0035 training cost= 0.135955056 test cost= 0.142598957\n",
      "Epoch: 0036 training cost= 0.133659789 test cost= 0.141541094\n",
      "Epoch: 0037 training cost= 0.131551745 test cost= 0.139062971\n",
      "Epoch: 0038 training cost= 0.129631875 test cost= 0.138207808\n",
      "Epoch: 0039 training cost= 0.127768221 test cost= 0.136712655\n",
      "Epoch: 0040 training cost= 0.125819624 test cost= 0.134839281\n",
      "Epoch: 0041 training cost= 0.123959245 test cost= 0.133675978\n",
      "Epoch: 0042 training cost= 0.122301912 test cost= 0.132181734\n",
      "Epoch: 0043 training cost= 0.120534767 test cost= 0.131363764\n",
      "Epoch: 0044 training cost= 0.118767195 test cost= 0.129389152\n",
      "Epoch: 0045 training cost= 0.117188697 test cost= 0.128735423\n",
      "Epoch: 0046 training cost= 0.115683377 test cost= 0.127208009\n",
      "Epoch: 0047 training cost= 0.114169817 test cost= 0.126245797\n",
      "Epoch: 0048 training cost= 0.112551767 test cost= 0.125187382\n",
      "Epoch: 0049 training cost= 0.111182756 test cost= 0.123616189\n",
      "Epoch: 0050 training cost= 0.109812813 test cost= 0.123108618\n",
      "Epoch: 0051 training cost= 0.108349492 test cost= 0.121918321\n",
      "Epoch: 0052 training cost= 0.107112331 test cost= 0.121100724\n",
      "Epoch: 0053 training cost= 0.105609970 test cost= 0.120063230\n",
      "Epoch: 0054 training cost= 0.104459879 test cost= 0.119191870\n",
      "Epoch: 0055 training cost= 0.103204938 test cost= 0.118733011\n",
      "Epoch: 0056 training cost= 0.101927400 test cost= 0.117823221\n",
      "Epoch: 0057 training cost= 0.100730694 test cost= 0.117280692\n",
      "Epoch: 0058 training cost= 0.099598008 test cost= 0.116848119\n",
      "Epoch: 0059 training cost= 0.098494794 test cost= 0.115534447\n",
      "Epoch: 0060 training cost= 0.097338923 test cost= 0.114804909\n",
      "Epoch: 0061 training cost= 0.096237678 test cost= 0.114117675\n",
      "Epoch: 0062 training cost= 0.095213867 test cost= 0.113370828\n",
      "Epoch: 0063 training cost= 0.094224737 test cost= 0.112330124\n",
      "Epoch: 0064 training cost= 0.093169321 test cost= 0.111210592\n",
      "Epoch: 0065 training cost= 0.092110547 test cost= 0.111180715\n",
      "Epoch: 0066 training cost= 0.091237299 test cost= 0.110348254\n",
      "Epoch: 0067 training cost= 0.090201754 test cost= 0.109763004\n",
      "Epoch: 0068 training cost= 0.089304032 test cost= 0.109325491\n",
      "Epoch: 0069 training cost= 0.088419053 test cost= 0.109647021\n",
      "Epoch: 0070 training cost= 0.087514165 test cost= 0.108155079\n",
      "Epoch: 0071 training cost= 0.086686835 test cost= 0.107820421\n",
      "Epoch: 0072 training cost= 0.085848213 test cost= 0.106843203\n",
      "Epoch: 0073 training cost= 0.084889586 test cost= 0.106901683\n",
      "Epoch: 0074 training cost= 0.084104054 test cost= 0.105514847\n",
      "Epoch: 0075 training cost= 0.083337937 test cost= 0.105507448\n",
      "Epoch: 0076 training cost= 0.082605059 test cost= 0.105562709\n",
      "Epoch: 0077 training cost= 0.081764528 test cost= 0.104517676\n",
      "Epoch: 0078 training cost= 0.080984419 test cost= 0.105428904\n",
      "Epoch: 0079 training cost= 0.080380899 test cost= 0.104127817\n",
      "Epoch: 0080 training cost= 0.079587179 test cost= 0.103196122\n",
      "Epoch: 0081 training cost= 0.078892390 test cost= 0.102850832\n",
      "Epoch: 0082 training cost= 0.078185592 test cost= 0.102695413\n",
      "Epoch: 0083 training cost= 0.077483562 test cost= 0.101897717\n",
      "Epoch: 0084 training cost= 0.076771828 test cost= 0.101687007\n",
      "Epoch: 0085 training cost= 0.076146443 test cost= 0.102010027\n",
      "Epoch: 0086 training cost= 0.075401929 test cost= 0.101561412\n",
      "Epoch: 0087 training cost= 0.074806815 test cost= 0.100325644\n",
      "Epoch: 0088 training cost= 0.074178041 test cost= 0.099982806\n",
      "Epoch: 0089 training cost= 0.073529020 test cost= 0.099389404\n",
      "Epoch: 0090 training cost= 0.072889711 test cost= 0.099757023\n",
      "Epoch: 0091 training cost= 0.072243350 test cost= 0.099790879\n",
      "Epoch: 0092 training cost= 0.071704399 test cost= 0.098860726\n",
      "Epoch: 0093 training cost= 0.071122700 test cost= 0.098551571\n",
      "Epoch: 0094 training cost= 0.070511605 test cost= 0.098242417\n",
      "Epoch: 0095 training cost= 0.069910847 test cost= 0.098143794\n",
      "Epoch: 0096 training cost= 0.069325442 test cost= 0.097891197\n",
      "Epoch: 0097 training cost= 0.068793137 test cost= 0.097366162\n",
      "Epoch: 0098 training cost= 0.068340987 test cost= 0.096716940\n",
      "Epoch: 0099 training cost= 0.067701218 test cost= 0.097143486\n",
      "Epoch: 0100 training cost= 0.067195636 test cost= 0.097607248\n",
      "Epoch: 0101 training cost= 0.066684803 test cost= 0.096486948\n",
      "Epoch: 0102 training cost= 0.066144753 test cost= 0.096325070\n",
      "Epoch: 0103 training cost= 0.065627120 test cost= 0.096123755\n",
      "Epoch: 0104 training cost= 0.065147267 test cost= 0.096428148\n",
      "Epoch: 0105 training cost= 0.064655819 test cost= 0.096004978\n",
      "Epoch: 0106 training cost= 0.064087727 test cost= 0.095263608\n",
      "Epoch: 0107 training cost= 0.063692581 test cost= 0.094861299\n",
      "Epoch: 0108 training cost= 0.063171071 test cost= 0.094879255\n",
      "Epoch: 0109 training cost= 0.062765187 test cost= 0.095480748\n",
      "Epoch: 0110 training cost= 0.062293736 test cost= 0.095211215\n",
      "Epoch: 0111 training cost= 0.061815101 test cost= 0.094626620\n",
      "Epoch: 0112 training cost= 0.061340839 test cost= 0.094389454\n",
      "Epoch: 0113 training cost= 0.060910414 test cost= 0.094373658\n",
      "Epoch: 0114 training cost= 0.060514645 test cost= 0.094380118\n",
      "Epoch: 0115 training cost= 0.060064702 test cost= 0.093822606\n",
      "Epoch: 0116 training cost= 0.059620529 test cost= 0.093562283\n",
      "Epoch: 0117 training cost= 0.059219498 test cost= 0.093457460\n",
      "Epoch: 0118 training cost= 0.058744446 test cost= 0.093334511\n",
      "Epoch: 0119 training cost= 0.058353454 test cost= 0.092815280\n",
      "Epoch: 0120 training cost= 0.057984186 test cost= 0.092867933\n",
      "Epoch: 0121 training cost= 0.057562440 test cost= 0.092454642\n",
      "Epoch: 0122 training cost= 0.057121114 test cost= 0.092531271\n",
      "Epoch: 0123 training cost= 0.056746819 test cost= 0.092266075\n",
      "Epoch: 0124 training cost= 0.056393341 test cost= 0.091317214\n",
      "Epoch: 0125 training cost= 0.055974952 test cost= 0.092047594\n",
      "Epoch: 0126 training cost= 0.055618697 test cost= 0.091327570\n",
      "Epoch: 0127 training cost= 0.055234149 test cost= 0.091187753\n",
      "Epoch: 0128 training cost= 0.054927464 test cost= 0.091227621\n",
      "Epoch: 0129 training cost= 0.054532168 test cost= 0.091080844\n",
      "Epoch: 0130 training cost= 0.054144232 test cost= 0.091077432\n",
      "Epoch: 0131 training cost= 0.053773012 test cost= 0.091117777\n",
      "Epoch: 0132 training cost= 0.053417232 test cost= 0.091279842\n",
      "Epoch: 0133 training cost= 0.053011697 test cost= 0.090798423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0134 training cost= 0.052662160 test cost= 0.090703920\n",
      "Epoch: 0135 training cost= 0.052373560 test cost= 0.091183268\n",
      "Epoch: 0136 training cost= 0.052051427 test cost= 0.090390757\n",
      "Epoch: 0137 training cost= 0.051670812 test cost= 0.090215638\n",
      "Epoch: 0138 training cost= 0.051403070 test cost= 0.090726137\n",
      "Epoch: 0139 training cost= 0.051052178 test cost= 0.090391323\n",
      "Epoch: 0140 training cost= 0.050706308 test cost= 0.090661392\n",
      "Epoch: 0141 training cost= 0.050348488 test cost= 0.090103909\n",
      "Epoch: 0142 training cost= 0.050023676 test cost= 0.090388015\n",
      "Epoch: 0143 training cost= 0.049764921 test cost= 0.090039387\n",
      "Epoch: 0144 training cost= 0.049453851 test cost= 0.089703523\n",
      "Epoch: 0145 training cost= 0.049101816 test cost= 0.089106478\n",
      "Epoch: 0146 training cost= 0.048743579 test cost= 0.089719467\n",
      "Epoch: 0147 training cost= 0.048563860 test cost= 0.090022340\n",
      "Epoch: 0148 training cost= 0.048229816 test cost= 0.089120418\n",
      "Epoch: 0149 training cost= 0.047934272 test cost= 0.089682803\n",
      "Epoch: 0150 training cost= 0.047582546 test cost= 0.088753164\n",
      "Epoch: 0151 training cost= 0.047280778 test cost= 0.089027442\n",
      "Epoch: 0152 training cost= 0.046997658 test cost= 0.089643441\n",
      "Epoch: 0153 training cost= 0.046750713 test cost= 0.088991806\n",
      "Epoch: 0154 training cost= 0.046492681 test cost= 0.089023180\n",
      "Epoch: 0155 training cost= 0.046152239 test cost= 0.088602893\n",
      "Epoch: 0156 training cost= 0.045916191 test cost= 0.088474855\n",
      "Epoch: 0157 training cost= 0.045631906 test cost= 0.088456571\n",
      "Epoch: 0158 training cost= 0.045346617 test cost= 0.088500552\n",
      "Epoch: 0159 training cost= 0.045059513 test cost= 0.089075223\n",
      "Epoch: 0160 training cost= 0.044804935 test cost= 0.088448547\n",
      "Epoch: 0161 training cost= 0.044552433 test cost= 0.088525355\n",
      "Epoch: 0162 training cost= 0.044295581 test cost= 0.088367008\n",
      "Epoch: 0163 training cost= 0.044004206 test cost= 0.088272028\n",
      "Epoch: 0164 training cost= 0.043735847 test cost= 0.088679686\n",
      "Epoch: 0165 training cost= 0.043394323 test cost= 0.088332266\n",
      "Epoch: 0166 training cost= 0.043265009 test cost= 0.088013709\n",
      "Epoch: 0167 training cost= 0.042996620 test cost= 0.088368900\n",
      "Epoch: 0168 training cost= 0.042688739 test cost= 0.088366322\n",
      "Epoch: 0169 training cost= 0.042485742 test cost= 0.088215739\n",
      "Epoch: 0170 training cost= 0.042232866 test cost= 0.087432846\n",
      "Epoch: 0171 training cost= 0.041981605 test cost= 0.087931149\n",
      "Epoch: 0172 training cost= 0.041738822 test cost= 0.088053413\n",
      "Epoch: 0173 training cost= 0.041485534 test cost= 0.087607123\n",
      "Epoch: 0174 training cost= 0.041290065 test cost= 0.087727457\n",
      "Epoch: 0175 training cost= 0.041025661 test cost= 0.087450601\n",
      "Epoch: 0176 training cost= 0.040757058 test cost= 0.087638758\n",
      "Epoch: 0177 training cost= 0.040570881 test cost= 0.087856621\n",
      "Epoch: 0178 training cost= 0.040263544 test cost= 0.087626174\n",
      "Epoch: 0179 training cost= 0.040096517 test cost= 0.087798387\n",
      "Epoch: 0180 training cost= 0.039883436 test cost= 0.087471716\n",
      "Epoch: 0181 training cost= 0.039641448 test cost= 0.087014958\n",
      "Epoch: 0182 training cost= 0.039422922 test cost= 0.087155618\n",
      "Epoch: 0183 training cost= 0.039172297 test cost= 0.087506056\n",
      "Epoch: 0184 training cost= 0.038918413 test cost= 0.087055899\n",
      "Epoch: 0185 training cost= 0.038790747 test cost= 0.087583974\n",
      "Epoch: 0186 training cost= 0.038530582 test cost= 0.087369815\n",
      "Epoch: 0187 training cost= 0.038335780 test cost= 0.086989649\n",
      "Epoch: 0188 training cost= 0.038082689 test cost= 0.086716324\n",
      "Epoch: 0189 training cost= 0.037850477 test cost= 0.087862149\n",
      "Epoch: 0190 training cost= 0.037670088 test cost= 0.087241851\n",
      "Epoch: 0191 training cost= 0.037490953 test cost= 0.086819030\n",
      "Epoch: 0192 training cost= 0.037247305 test cost= 0.086992145\n",
      "Epoch: 0193 training cost= 0.037038478 test cost= 0.087307572\n",
      "Epoch: 0194 training cost= 0.036840226 test cost= 0.086956739\n",
      "Epoch: 0195 training cost= 0.036667578 test cost= 0.087105460\n",
      "Epoch: 0196 training cost= 0.036480725 test cost= 0.086943142\n",
      "Epoch: 0197 training cost= 0.036226364 test cost= 0.086413741\n",
      "Epoch: 0198 training cost= 0.036093310 test cost= 0.086664543\n",
      "Epoch: 0199 training cost= 0.035783490 test cost= 0.086827196\n",
      "Epoch: 0200 training cost= 0.035644233 test cost= 0.086984135\n",
      "Epoch: 0201 training cost= 0.035451283 test cost= 0.086703897\n",
      "Epoch: 0202 training cost= 0.035273217 test cost= 0.087214738\n",
      "Epoch: 0203 training cost= 0.035054011 test cost= 0.086640805\n",
      "Epoch: 0204 training cost= 0.034895373 test cost= 0.086681984\n",
      "Epoch: 0205 training cost= 0.034710056 test cost= 0.086702466\n",
      "Epoch: 0206 training cost= 0.034522322 test cost= 0.086944111\n",
      "Epoch: 0207 training cost= 0.034316536 test cost= 0.086864285\n",
      "Epoch: 0208 training cost= 0.034168609 test cost= 0.086893000\n",
      "Epoch: 0209 training cost= 0.033947097 test cost= 0.086579233\n",
      "Epoch: 0210 training cost= 0.033803012 test cost= 0.086714603\n",
      "Epoch: 0211 training cost= 0.033618312 test cost= 0.086176343\n",
      "Epoch: 0212 training cost= 0.033378793 test cost= 0.086572848\n",
      "Epoch: 0213 training cost= 0.033262231 test cost= 0.086785130\n",
      "Epoch: 0214 training cost= 0.033069564 test cost= 0.086885668\n",
      "Epoch: 0215 training cost= 0.032893780 test cost= 0.086976670\n",
      "Epoch: 0216 training cost= 0.032753934 test cost= 0.086937144\n",
      "Epoch: 0217 training cost= 0.032531467 test cost= 0.086703122\n",
      "Epoch: 0218 training cost= 0.032382381 test cost= 0.086653292\n",
      "Epoch: 0219 training cost= 0.032239206 test cost= 0.086343654\n",
      "Epoch: 0220 training cost= 0.032050632 test cost= 0.086280212\n",
      "Epoch: 0221 training cost= 0.031926387 test cost= 0.087032765\n",
      "Epoch: 0222 training cost= 0.031726062 test cost= 0.086608522\n",
      "Epoch: 0223 training cost= 0.031562695 test cost= 0.086427122\n",
      "Epoch: 0224 training cost= 0.031390159 test cost= 0.086328045\n",
      "Epoch: 0225 training cost= 0.031232004 test cost= 0.086526170\n",
      "Epoch: 0226 training cost= 0.031012043 test cost= 0.086659789\n",
      "Epoch: 0227 training cost= 0.030887584 test cost= 0.086903043\n",
      "Epoch: 0228 training cost= 0.030733845 test cost= 0.086535878\n",
      "Epoch: 0229 training cost= 0.030581797 test cost= 0.086304553\n",
      "Epoch: 0230 training cost= 0.030428716 test cost= 0.086427234\n",
      "Epoch: 0231 training cost= 0.030279422 test cost= 0.086761340\n",
      "Epoch: 0232 training cost= 0.030113683 test cost= 0.086413138\n",
      "Epoch: 0233 training cost= 0.029976177 test cost= 0.086665086\n",
      "Epoch: 0234 training cost= 0.029825791 test cost= 0.086704880\n",
      "Epoch: 0235 training cost= 0.029638023 test cost= 0.086756006\n",
      "Epoch: 0236 training cost= 0.029487815 test cost= 0.086841233\n",
      "Epoch: 0237 training cost= 0.029341199 test cost= 0.087243974\n",
      "Epoch: 0238 training cost= 0.029168859 test cost= 0.087038927\n",
      "Epoch: 0239 training cost= 0.029056643 test cost= 0.086734720\n",
      "Epoch: 0240 training cost= 0.028870566 test cost= 0.086969055\n",
      "Epoch: 0241 training cost= 0.028745466 test cost= 0.086876944\n",
      "Epoch: 0242 training cost= 0.028614352 test cost= 0.087452307\n",
      "Epoch: 0243 training cost= 0.028483850 test cost= 0.086618289\n",
      "Epoch: 0244 training cost= 0.028292964 test cost= 0.087058365\n",
      "Epoch: 0245 training cost= 0.028190543 test cost= 0.086707287\n",
      "Epoch: 0246 training cost= 0.028007387 test cost= 0.086754650\n",
      "Epoch: 0247 training cost= 0.027901460 test cost= 0.086818419\n",
      "Epoch: 0248 training cost= 0.027748336 test cost= 0.086296342\n",
      "Epoch: 0249 training cost= 0.027583824 test cost= 0.086620323\n",
      "Epoch: 0250 training cost= 0.027509616 test cost= 0.086780235\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # Initializing the variables\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        train_avg_loss = 0.0\n",
    "        total_batches = int(mnist.train.num_examples / batch_size)\n",
    "        # loop over all batches\n",
    "        for i in range(total_batches):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            train_avg_loss += c / total_batches  # Compute average loss\n",
    "        train_loss_list.append(train_avg_loss)\n",
    "        test_avg_loss = sess.run(cost, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        test_loss_list.append(test_avg_loss)\n",
    "        print('Epoch: %04d' % (epoch + 1), 'training cost=', '{:.9f}'.format(train_avg_loss), 'test cost=', \n",
    "             '{:.9f}'.format(test_avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_list = np.array(train_loss_list)\n",
    "test_loss_list = np.array(test_loss_list)\n",
    "x = np.arange(0, 250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))  # set image size\n",
    "plt.plot(x, train_loss_list, c='r', ls='dotted')\n",
    "plt.plot(x, test_loss_list, c='g')\n",
    "plt.xlim(0, 260)\n",
    "plt.ylim(0, 0.8)\n",
    "plt.legend(['training loss', 'test loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
